{
  "generated_at": "2026-02-21T04:35:49.588474+00:00",
  "n_queries": 35,
  "approaches": [
    "Hybrid",
    "Hybrid+Expand",
    "Hybrid+RRF",
    "BM25",
    "Semantic",
    "LLM:gemini-2.0-flash-001",
    "LLM:llama-3.1-nemotron-70b",
    "LLM:llama-3.3-70b"
  ],
  "per_query": [
    {
      "query": "Who is Ramesh Raskar?",
      "level": "L1",
      "scoring": "normal",
      "keywords": [
        "ramesh",
        "raskar",
        "professor",
        "mit"
      ],
      "top_k": 5,
      "approaches": {
        "Hybrid": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "BM25": {
          "recall": 0.75,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.75,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "Semantic": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        }
      }
    },
    {
      "query": "Are there any course videos?",
      "level": "L1",
      "scoring": "normal",
      "keywords": [
        "video",
        "youtube"
      ],
      "top_k": 5,
      "approaches": {
        "Hybrid": {
          "recall": 1.0,
          "mrr": 0.3333333333333333,
          "ndcg": 0.5,
          "effective_recall": 1.0,
          "effective_mrr": 0.3333333333333333,
          "effective_ndcg": 0.5,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 1.0,
          "mrr": 0.3333333333333333,
          "ndcg": 0.5,
          "effective_recall": 1.0,
          "effective_mrr": 0.3333333333333333,
          "effective_ndcg": 0.5,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "BM25": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "Semantic": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        }
      }
    },
    {
      "query": "What is the course about?",
      "level": "L1",
      "scoring": "normal",
      "keywords": [
        "ai",
        "venture",
        "prototyping",
        "hands-on"
      ],
      "top_k": 5,
      "approaches": {
        "Hybrid": {
          "recall": 0.5,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.5,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 0.5,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.5,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 0.5,
          "mrr": 1.0,
          "ndcg": 0.9828920819566879,
          "effective_recall": 0.5,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9828920819566879,
          "passed": true
        },
        "BM25": {
          "recall": 0.75,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.75,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "Semantic": {
          "recall": 0.75,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.75,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.8919478197221425,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8919478197221425,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.5,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.5,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.5,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.5,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        }
      }
    },
    {
      "query": "How do I register for the course?",
      "level": "L2",
      "scoring": "normal",
      "keywords": [
        "register",
        "questionnaire",
        "apply",
        "form"
      ],
      "top_k": 5,
      "approaches": {
        "Hybrid": {
          "recall": 0.75,
          "mrr": 0.3333333333333333,
          "ndcg": 0.5976315487360696,
          "effective_recall": 0.75,
          "effective_mrr": 0.3333333333333333,
          "effective_ndcg": 0.5976315487360696,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 0.75,
          "mrr": 0.3333333333333333,
          "ndcg": 0.5976315487360696,
          "effective_recall": 0.75,
          "effective_mrr": 0.3333333333333333,
          "effective_ndcg": 0.5976315487360696,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 0.75,
          "mrr": 1.0,
          "ndcg": 0.9699225363013644,
          "effective_recall": 0.75,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9699225363013644,
          "passed": true
        },
        "BM25": {
          "recall": 0.75,
          "mrr": 1.0,
          "ndcg": 0.8986776544421414,
          "effective_recall": 0.75,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8986776544421414,
          "passed": true
        },
        "Semantic": {
          "recall": 0.75,
          "mrr": 0.3333333333333333,
          "ndcg": 0.4573369727327457,
          "effective_recall": 0.75,
          "effective_mrr": 0.3333333333333333,
          "effective_ndcg": 0.4573369727327457,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.75,
          "mrr": 1.0,
          "ndcg": 0.9121656860366328,
          "effective_recall": 0.75,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9121656860366328,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.75,
          "mrr": 1.0,
          "ndcg": 0.9049765583210164,
          "effective_recall": 0.75,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9049765583210164,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.75,
          "mrr": 1.0,
          "ndcg": 0.9121656860366328,
          "effective_recall": 0.75,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9121656860366328,
          "passed": true
        }
      }
    },
    {
      "query": "What is the course format for Fall 2025?",
      "level": "L2",
      "scoring": "normal",
      "keywords": [
        "venture studio",
        "agentic",
        "demo day"
      ],
      "top_k": 5,
      "approaches": {
        "Hybrid": {
          "recall": 0.6666666666666666,
          "mrr": 1.0,
          "ndcg": 0.9920466006454152,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9920466006454152,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 0.6666666666666666,
          "mrr": 1.0,
          "ndcg": 0.9920466006454152,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9920466006454152,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 0.6666666666666666,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "BM25": {
          "recall": 0.6666666666666666,
          "mrr": 1.0,
          "ndcg": 0.971408902537385,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.971408902537385,
          "passed": true
        },
        "Semantic": {
          "recall": 0.6666666666666666,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.6666666666666666,
          "mrr": 1.0,
          "ndcg": 0.8656392231763174,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8656392231763174,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.6666666666666666,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.8375161037724468,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8375161037724468,
          "passed": true
        }
      }
    },
    {
      "query": "What venture capital firms are involved as speakers or mentors?",
      "level": "L3",
      "scoring": "normal",
      "keywords": [
        "khosla",
        "lux",
        "link ventures",
        "two lanterns",
        "pillar",
        "e14"
      ],
      "top_k": 15,
      "approaches": {
        "Hybrid": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.7671980430548917,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7671980430548917,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.9297949982523477,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9297949982523477,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.6272607566348145,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.6272607566348145,
          "passed": true
        },
        "BM25": {
          "recall": 0.8333333333333334,
          "mrr": 1.0,
          "ndcg": 0.9827994861811935,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9827994861811935,
          "passed": true
        },
        "Semantic": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.5531239834838553,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.5531239834838553,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.7033736910334266,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7033736910334266,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.6901332867457537,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.6901332867457537,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.9132595666297368,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9132595666297368,
          "passed": true
        }
      }
    },
    {
      "query": "Who were the venture capital speakers in Fall 2023?",
      "level": "L3",
      "scoring": "normal",
      "keywords": [
        "khosla",
        "lux",
        "link",
        "e14",
        "pillar"
      ],
      "top_k": 15,
      "approaches": {
        "Hybrid": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.6022440725213158,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.6022440725213158,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.6672365503089726,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.6672365503089726,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.6415596441058588,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.6415596441058588,
          "passed": true
        },
        "BM25": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.9595981238976526,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9595981238976526,
          "passed": true
        },
        "Semantic": {
          "recall": 0.2,
          "mrr": 1.0,
          "ndcg": 0.8221120471878671,
          "effective_recall": 0.2,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8221120471878671,
          "passed": false
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.7614851882563043,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7614851882563043,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.5713939514994553,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.5713939514994553,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.8686633200819412,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8686633200819412,
          "passed": true
        }
      }
    },
    {
      "query": "How has the course name changed across semesters?",
      "level": "L3",
      "scoring": "normal",
      "keywords": [
        "web3",
        "venture",
        "agentic",
        "foundations"
      ],
      "top_k": 5,
      "approaches": {
        "Hybrid": {
          "recall": 0.75,
          "mrr": 1.0,
          "ndcg": 0.8442355845243696,
          "effective_recall": 0.75,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8442355845243696,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 0.75,
          "mrr": 1.0,
          "ndcg": 0.8442355845243696,
          "effective_recall": 0.75,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8442355845243696,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 0.75,
          "mrr": 1.0,
          "ndcg": 0.982619653523767,
          "effective_recall": 0.75,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.982619653523767,
          "passed": true
        },
        "BM25": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "Semantic": {
          "recall": 0.75,
          "mrr": 1.0,
          "ndcg": 0.6776636931349654,
          "effective_recall": 0.75,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.6776636931349654,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.75,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.75,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.75,
          "mrr": 1.0,
          "ndcg": 0.9813883936133462,
          "effective_recall": 0.75,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9813883936133462,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.75,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.75,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        }
      }
    },
    {
      "query": "What changed between the 2025 and 2026 versions of the course?",
      "level": "L3",
      "scoring": "normal",
      "keywords": [
        "agentic",
        "autonomous",
        "venture studio",
        "foundations",
        "spring 2026",
        "spring 2025"
      ],
      "top_k": 5,
      "approaches": {
        "Hybrid": {
          "recall": 0.5,
          "mrr": 1.0,
          "ndcg": 0.8401498110374593,
          "effective_recall": 0.5,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8401498110374593,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 0.5,
          "mrr": 1.0,
          "ndcg": 0.8401498110374593,
          "effective_recall": 0.5,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8401498110374593,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 0.5,
          "mrr": 1.0,
          "ndcg": 0.7040663144958564,
          "effective_recall": 0.5,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7040663144958564,
          "passed": true
        },
        "BM25": {
          "recall": 0.5,
          "mrr": 0.5,
          "ndcg": 0.567207416956871,
          "effective_recall": 0.5,
          "effective_mrr": 0.5,
          "effective_ndcg": 0.567207416956871,
          "passed": true
        },
        "Semantic": {
          "recall": 0.5,
          "mrr": 1.0,
          "ndcg": 0.8447122853992027,
          "effective_recall": 0.5,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8447122853992027,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.3333333333333333,
          "mrr": 1.0,
          "ndcg": 0.8599797111848092,
          "effective_recall": 0.3333333333333333,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8599797111848092,
          "passed": false
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.3333333333333333,
          "mrr": 1.0,
          "ndcg": 0.9469024295259745,
          "effective_recall": 0.3333333333333333,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9469024295259745,
          "passed": false
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.5,
          "mrr": 0.5,
          "ndcg": 0.7242206596550013,
          "effective_recall": 0.5,
          "effective_mrr": 0.5,
          "effective_ndcg": 0.7242206596550013,
          "passed": true
        }
      }
    },
    {
      "query": "What is NANDA and why does Raskar think it matters?",
      "level": "L4",
      "scoring": "normal",
      "keywords": [
        "nanda",
        "network",
        "agent",
        "decentralized",
        "internet"
      ],
      "top_k": 5,
      "approaches": {
        "Hybrid": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.6673385207601783,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.6673385207601783,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.6673385207601783,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.6673385207601783,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.6673385207601783,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.6673385207601783,
          "passed": true
        },
        "BM25": {
          "recall": 0.4,
          "mrr": 1.0,
          "ndcg": 0.8223779611386884,
          "effective_recall": 0.4,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8223779611386884,
          "passed": true
        },
        "Semantic": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.9735792424866951,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9735792424866951,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.9359980548891793,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9359980548891793,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.6673385207601783,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.6673385207601783,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        }
      }
    },
    {
      "query": "What did Raskar say about privacy and decentralized AI?",
      "level": "L4",
      "scoring": "normal",
      "keywords": [
        "privacy",
        "decentralized",
        "data",
        "machine learning"
      ],
      "top_k": 5,
      "approaches": {
        "Hybrid": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.9629027936988324,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9629027936988324,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.9629027936988324,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9629027936988324,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.9066180787084464,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9066180787084464,
          "passed": true
        },
        "BM25": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.9488136009556424,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9488136009556424,
          "passed": true
        },
        "Semantic": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.9629027936988324,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9629027936988324,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.7302937468156797,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7302937468156797,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.9629027936988324,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9629027936988324,
          "passed": true
        }
      }
    },
    {
      "query": "What companies like Mitsubishi were judges or partners at Demo Day?",
      "level": "L5",
      "scoring": "normal",
      "keywords": [
        "mitsubishi",
        "judge",
        "partner",
        "corporate"
      ],
      "top_k": 5,
      "approaches": {
        "Hybrid": {
          "recall": 0.75,
          "mrr": 1.0,
          "ndcg": 0.7770227215242603,
          "effective_recall": 0.75,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7770227215242603,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 0.75,
          "mrr": 1.0,
          "ndcg": 0.7979168917078058,
          "effective_recall": 0.75,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7979168917078058,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 0.75,
          "mrr": 1.0,
          "ndcg": 0.9121656860366328,
          "effective_recall": 0.75,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9121656860366328,
          "passed": true
        },
        "BM25": {
          "recall": 0.75,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.75,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "Semantic": {
          "recall": 0.75,
          "mrr": 1.0,
          "ndcg": 0.7979168917078058,
          "effective_recall": 0.75,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7979168917078058,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.5,
          "mrr": 1.0,
          "ndcg": 0.8447122853992027,
          "effective_recall": 0.5,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8447122853992027,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.75,
          "mrr": 1.0,
          "ndcg": 0.8239560888032269,
          "effective_recall": 0.75,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8239560888032269,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.25,
          "mrr": 0.5,
          "ndcg": 0.7328286204777911,
          "effective_recall": 0.25,
          "effective_mrr": 0.5,
          "effective_ndcg": 0.7328286204777911,
          "passed": false
        }
      }
    },
    {
      "query": "How does Raskar compare the internet evolution to the agentic web?",
      "level": "L5",
      "scoring": "normal",
      "keywords": [
        "internet",
        "worldwide web",
        "mainframe",
        "intranet",
        "agentic"
      ],
      "top_k": 5,
      "approaches": {
        "Hybrid": {
          "recall": 0.6,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.6,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 0.6,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.6,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 0.8,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.8,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "BM25": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "Semantic": {
          "recall": 0.8,
          "mrr": 1.0,
          "ndcg": 0.7521728881423634,
          "effective_recall": 0.8,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7521728881423634,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.8,
          "mrr": 1.0,
          "ndcg": 0.7770227215242603,
          "effective_recall": 0.8,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7770227215242603,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.8,
          "mrr": 1.0,
          "ndcg": 0.7770227215242603,
          "effective_recall": 0.8,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7770227215242603,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.8,
          "mrr": 1.0,
          "ndcg": 0.7770227215242603,
          "effective_recall": 0.8,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7770227215242603,
          "passed": true
        }
      }
    },
    {
      "query": "What healthcare or medical examples did speakers discuss?",
      "level": "L5",
      "scoring": "normal",
      "keywords": [
        "health",
        "medical",
        "patient",
        "hospital",
        "diabetic",
        "chest"
      ],
      "top_k": 5,
      "approaches": {
        "Hybrid": {
          "recall": 0.5,
          "mrr": 1.0,
          "ndcg": 0.7521866188906461,
          "effective_recall": 0.5,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7521866188906461,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 0.5,
          "mrr": 1.0,
          "ndcg": 0.7521866188906461,
          "effective_recall": 0.5,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7521866188906461,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 0.6666666666666666,
          "mrr": 1.0,
          "ndcg": 0.7320886311979027,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7320886311979027,
          "passed": true
        },
        "BM25": {
          "recall": 0.6666666666666666,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "Semantic": {
          "recall": 0.5,
          "mrr": 1.0,
          "ndcg": 0.7521866188906461,
          "effective_recall": 0.5,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7521866188906461,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.16666666666666666,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.16666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": false
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.16666666666666666,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.16666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": false
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.16666666666666666,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.16666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": false
        }
      }
    },
    {
      "query": "Who funds early-stage startups at the course?",
      "level": "L6",
      "scoring": "normal",
      "keywords": [
        "khosla",
        "lux",
        "link ventures",
        "e14",
        "pillar",
        "venture"
      ],
      "top_k": 15,
      "approaches": {
        "Hybrid": {
          "recall": 0.8333333333333334,
          "mrr": 1.0,
          "ndcg": 0.8174152298079348,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8174152298079348,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 0.8333333333333334,
          "mrr": 1.0,
          "ndcg": 0.8174152298079348,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8174152298079348,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 0.8333333333333334,
          "mrr": 1.0,
          "ndcg": 0.8796810374691769,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8796810374691769,
          "passed": true
        },
        "BM25": {
          "recall": 0.8333333333333334,
          "mrr": 1.0,
          "ndcg": 0.8307469081123,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8307469081123,
          "passed": true
        },
        "Semantic": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.6838554026395006,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.6838554026395006,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.8333333333333334,
          "mrr": 1.0,
          "ndcg": 0.881282782391275,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.881282782391275,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.8333333333333334,
          "mrr": 1.0,
          "ndcg": 0.881282782391275,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.881282782391275,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.8333333333333334,
          "mrr": 1.0,
          "ndcg": 0.881282782391275,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.881282782391275,
          "passed": true
        }
      }
    },
    {
      "query": "What cutting-edge tech topics are covered in lectures?",
      "level": "L6",
      "scoring": "normal",
      "keywords": [
        "agentic",
        "autonomous",
        "nanda",
        "decentralized",
        "web3",
        "blockchain"
      ],
      "top_k": 5,
      "approaches": {
        "Hybrid": {
          "recall": 0.0,
          "mrr": 0.0,
          "ndcg": 1.0,
          "effective_recall": 0.0,
          "effective_mrr": 0.0,
          "effective_ndcg": 1.0,
          "passed": false
        },
        "Hybrid+Expand": {
          "recall": 0.0,
          "mrr": 0.0,
          "ndcg": 1.0,
          "effective_recall": 0.0,
          "effective_mrr": 0.0,
          "effective_ndcg": 1.0,
          "passed": false
        },
        "Hybrid+RRF": {
          "recall": 0.0,
          "mrr": 0.0,
          "ndcg": 1.0,
          "effective_recall": 0.0,
          "effective_mrr": 0.0,
          "effective_ndcg": 1.0,
          "passed": false
        },
        "BM25": {
          "recall": 0.16666666666666666,
          "mrr": 0.2,
          "ndcg": 0.38685280723454163,
          "effective_recall": 0.16666666666666666,
          "effective_mrr": 0.2,
          "effective_ndcg": 0.38685280723454163,
          "passed": false
        },
        "Semantic": {
          "recall": 0.0,
          "mrr": 0.0,
          "ndcg": 1.0,
          "effective_recall": 0.0,
          "effective_mrr": 0.0,
          "effective_ndcg": 1.0,
          "passed": false
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.0,
          "mrr": 0.0,
          "ndcg": 1.0,
          "effective_recall": 0.0,
          "effective_mrr": 0.0,
          "effective_ndcg": 1.0,
          "passed": false
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.0,
          "mrr": 0.0,
          "ndcg": 1.0,
          "effective_recall": 0.0,
          "effective_mrr": 0.0,
          "effective_ndcg": 1.0,
          "passed": false
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.0,
          "mrr": 0.0,
          "ndcg": 1.0,
          "effective_recall": 0.0,
          "effective_mrr": 0.0,
          "effective_ndcg": 1.0,
          "passed": false
        }
      }
    },
    {
      "query": "Who helps students refine their business ideas?",
      "level": "L6",
      "scoring": "normal",
      "keywords": [
        "mentor",
        "speaker",
        "instructor",
        "co-instructor",
        "judge",
        "catalyst"
      ],
      "top_k": 10,
      "approaches": {
        "Hybrid": {
          "recall": 0.6666666666666666,
          "mrr": 0.3333333333333333,
          "ndcg": 0.6126858339449328,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 0.3333333333333333,
          "effective_ndcg": 0.6126858339449328,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 0.6666666666666666,
          "mrr": 0.3333333333333333,
          "ndcg": 0.6126858339449328,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 0.3333333333333333,
          "effective_ndcg": 0.6126858339449328,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 0.6666666666666666,
          "mrr": 1.0,
          "ndcg": 0.8641073220006465,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8641073220006465,
          "passed": true
        },
        "BM25": {
          "recall": 0.8333333333333334,
          "mrr": 1.0,
          "ndcg": 0.7527035338965439,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7527035338965439,
          "passed": true
        },
        "Semantic": {
          "recall": 0.6666666666666666,
          "mrr": 0.3333333333333333,
          "ndcg": 0.5106716842493384,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 0.3333333333333333,
          "effective_ndcg": 0.5106716842493384,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.6666666666666666,
          "mrr": 0.3333333333333333,
          "ndcg": 0.6279040080595649,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 0.3333333333333333,
          "effective_ndcg": 0.6279040080595649,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.6666666666666666,
          "mrr": 0.3333333333333333,
          "ndcg": 0.6279040080595649,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 0.3333333333333333,
          "effective_ndcg": 0.6279040080595649,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.6666666666666666,
          "mrr": 0.3333333333333333,
          "ndcg": 0.6279040080595649,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 0.3333333333333333,
          "effective_ndcg": 0.6279040080595649,
          "passed": true
        }
      }
    },
    {
      "query": "How do teams show off their work at the end of the semester?",
      "level": "L6",
      "scoring": "normal",
      "keywords": [
        "demo day",
        "pitch",
        "presentation",
        "showcase",
        "judge"
      ],
      "top_k": 5,
      "approaches": {
        "Hybrid": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.8241377469002206,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8241377469002206,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.8241377469002206,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8241377469002206,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.8149343938070834,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8149343938070834,
          "passed": true
        },
        "BM25": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.8056979221630077,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8056979221630077,
          "passed": true
        },
        "Semantic": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.8241377469002206,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8241377469002206,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.8241377469002206,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8241377469002206,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.8241377469002206,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8241377469002206,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.8241377469002206,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8241377469002206,
          "passed": true
        }
      }
    },
    {
      "query": "What privacy-preserving machine learning method was invented at MIT?",
      "level": "L6",
      "scoring": "normal",
      "keywords": [
        "split learning",
        "federated",
        "privacy",
        "no peak",
        "decentralized"
      ],
      "top_k": 5,
      "approaches": {
        "Hybrid": {
          "recall": 0.4,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.4,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 0.4,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.4,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 0.8,
          "mrr": 1.0,
          "ndcg": 0.8300014060367712,
          "effective_recall": 0.8,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8300014060367712,
          "passed": true
        },
        "BM25": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.9720982957292578,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9720982957292578,
          "passed": true
        },
        "Semantic": {
          "recall": 0.4,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.4,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.0,
          "mrr": 0.0,
          "ndcg": 1.0,
          "effective_recall": 0.0,
          "effective_mrr": 0.0,
          "effective_ndcg": 1.0,
          "passed": false
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.0,
          "mrr": 0.0,
          "ndcg": 1.0,
          "effective_recall": 0.0,
          "effective_mrr": 0.0,
          "effective_ndcg": 1.0,
          "passed": false
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.0,
          "mrr": 0.0,
          "ndcg": 1.0,
          "effective_recall": 0.0,
          "effective_mrr": 0.0,
          "effective_ndcg": 1.0,
          "passed": false
        }
      }
    },
    {
      "query": "Which speakers or mentors appeared in both Fall 2023 and Spring 2024?",
      "level": "L7",
      "scoring": "normal",
      "keywords": [
        "raskar",
        "ramesh",
        "john",
        "werner",
        "habib",
        "hadad",
        "link"
      ],
      "top_k": 15,
      "approaches": {
        "Hybrid": {
          "recall": 0.42857142857142855,
          "mrr": 0.125,
          "ndcg": 0.3458369414795075,
          "effective_recall": 0.42857142857142855,
          "effective_mrr": 0.125,
          "effective_ndcg": 0.3458369414795075,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 0.42857142857142855,
          "mrr": 0.125,
          "ndcg": 0.3458369414795075,
          "effective_recall": 0.42857142857142855,
          "effective_mrr": 0.125,
          "effective_ndcg": 0.3458369414795075,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 0.7142857142857143,
          "mrr": 0.5,
          "ndcg": 0.6649501334973374,
          "effective_recall": 0.7142857142857143,
          "effective_mrr": 0.5,
          "effective_ndcg": 0.6649501334973374,
          "passed": true
        },
        "BM25": {
          "recall": 0.8571428571428571,
          "mrr": 1.0,
          "ndcg": 0.919399865400546,
          "effective_recall": 0.8571428571428571,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.919399865400546,
          "passed": true
        },
        "Semantic": {
          "recall": 0.2857142857142857,
          "mrr": 0.07692307692307693,
          "ndcg": 0.360691176496464,
          "effective_recall": 0.2857142857142857,
          "effective_mrr": 0.07692307692307693,
          "effective_ndcg": 0.360691176496464,
          "passed": false
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.2857142857142857,
          "mrr": 0.25,
          "ndcg": 0.43954268380428807,
          "effective_recall": 0.2857142857142857,
          "effective_mrr": 0.25,
          "effective_ndcg": 0.43954268380428807,
          "passed": false
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.2857142857142857,
          "mrr": 0.25,
          "ndcg": 0.43954268380428807,
          "effective_recall": 0.2857142857142857,
          "effective_mrr": 0.25,
          "effective_ndcg": 0.43954268380428807,
          "passed": false
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.2857142857142857,
          "mrr": 0.25,
          "ndcg": 0.43954268380428807,
          "effective_recall": 0.2857142857142857,
          "effective_mrr": 0.25,
          "effective_ndcg": 0.43954268380428807,
          "passed": false
        }
      }
    },
    {
      "query": "How has the number of student teams changed across semesters?",
      "level": "L7",
      "scoring": "normal",
      "keywords": [
        "15",
        "24",
        "38",
        "teams",
        "presenting"
      ],
      "top_k": 5,
      "approaches": {
        "Hybrid": {
          "recall": 0.4,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.4,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 0.4,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.4,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 0.4,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.4,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "BM25": {
          "recall": 0.8,
          "mrr": 1.0,
          "ndcg": 0.9069783029220914,
          "effective_recall": 0.8,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9069783029220914,
          "passed": true
        },
        "Semantic": {
          "recall": 0.4,
          "mrr": 1.0,
          "ndcg": 0.9605753368118397,
          "effective_recall": 0.4,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9605753368118397,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.4,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.4,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.4,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.4,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.4,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.4,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        }
      }
    },
    {
      "query": "What real-world companies were both judges and corporate partners at demo days?",
      "level": "L7",
      "scoring": "normal",
      "keywords": [
        "mitsubishi",
        "state street",
        "ey",
        "mass challenge"
      ],
      "top_k": 15,
      "approaches": {
        "Hybrid": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.8011166442354041,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8011166442354041,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.8045634000992654,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8045634000992654,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 0.75,
          "mrr": 1.0,
          "ndcg": 0.8062497036910624,
          "effective_recall": 0.75,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8062497036910624,
          "passed": true
        },
        "BM25": {
          "recall": 0.25,
          "mrr": 0.5,
          "ndcg": 0.8663422763540115,
          "effective_recall": 0.25,
          "effective_mrr": 0.5,
          "effective_ndcg": 0.8663422763540115,
          "passed": false
        },
        "Semantic": {
          "recall": 0.5,
          "mrr": 1.0,
          "ndcg": 0.9170245493900888,
          "effective_recall": 0.5,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9170245493900888,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.5,
          "mrr": 1.0,
          "ndcg": 0.9061710886726135,
          "effective_recall": 0.5,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9061710886726135,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.5,
          "mrr": 1.0,
          "ndcg": 0.9061710886726135,
          "effective_recall": 0.5,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9061710886726135,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.5,
          "mrr": 1.0,
          "ndcg": 0.9061710886726135,
          "effective_recall": 0.5,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9061710886726135,
          "passed": true
        }
      }
    },
    {
      "query": "Did the course evaluation criteria change between Spring 2023 and Fall 2025?",
      "level": "L7",
      "scoring": "normal",
      "keywords": [
        "impact",
        "unique",
        "complete",
        "demo",
        "judge",
        "gigas scale"
      ],
      "top_k": 5,
      "approaches": {
        "Hybrid": {
          "recall": 0.8333333333333334,
          "mrr": 1.0,
          "ndcg": 0.8080267481237329,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8080267481237329,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 0.8333333333333334,
          "mrr": 1.0,
          "ndcg": 0.8080267481237329,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8080267481237329,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 0.3333333333333333,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.3333333333333333,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": false
        },
        "BM25": {
          "recall": 0.3333333333333333,
          "mrr": 1.0,
          "ndcg": 0.7960767356132932,
          "effective_recall": 0.3333333333333333,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7960767356132932,
          "passed": false
        },
        "Semantic": {
          "recall": 0.8333333333333334,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.8333333333333334,
          "mrr": 1.0,
          "ndcg": 0.7932495804570024,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7932495804570024,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.8333333333333334,
          "mrr": 1.0,
          "ndcg": 0.7932495804570024,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7932495804570024,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.8333333333333334,
          "mrr": 1.0,
          "ndcg": 0.7932495804570024,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7932495804570024,
          "passed": true
        }
      }
    },
    {
      "query": "What is the tuition cost for the AI Studio course?",
      "level": "L8",
      "scoring": "inverse",
      "keywords": [
        "tuition",
        "cost",
        "fee",
        "price",
        "dollar",
        "pay"
      ],
      "top_k": 5,
      "approaches": {
        "Hybrid": {
          "recall": 0.5,
          "mrr": 0.5,
          "ndcg": 0.6728853390803203,
          "effective_recall": 0.5,
          "effective_mrr": 0.5,
          "effective_ndcg": 0.32711466091967967,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 0.5,
          "mrr": 0.5,
          "ndcg": 0.6728853390803203,
          "effective_recall": 0.5,
          "effective_mrr": 0.5,
          "effective_ndcg": 0.32711466091967967,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 0.16666666666666666,
          "mrr": 0.2,
          "ndcg": 0.38685280723454163,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 0.8,
          "effective_ndcg": 0.6131471927654584,
          "passed": true
        },
        "BM25": {
          "recall": 0.5,
          "mrr": 1.0,
          "ndcg": 0.9238850086262383,
          "effective_recall": 0.5,
          "effective_mrr": 0.0,
          "effective_ndcg": 0.07611499137376165,
          "passed": true
        },
        "Semantic": {
          "recall": 0.5,
          "mrr": 0.5,
          "ndcg": 0.6728853390803203,
          "effective_recall": 0.5,
          "effective_mrr": 0.5,
          "effective_ndcg": 0.32711466091967967,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.5,
          "mrr": 0.25,
          "ndcg": 0.46238363047462905,
          "effective_recall": 0.5,
          "effective_mrr": 0.75,
          "effective_ndcg": 0.537616369525371,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.5,
          "mrr": 0.25,
          "ndcg": 0.46238363047462905,
          "effective_recall": 0.5,
          "effective_mrr": 0.75,
          "effective_ndcg": 0.537616369525371,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.5,
          "mrr": 0.25,
          "ndcg": 0.46238363047462905,
          "effective_recall": 0.5,
          "effective_mrr": 0.75,
          "effective_ndcg": 0.537616369525371,
          "passed": true
        }
      }
    },
    {
      "query": "What programming languages are required as prerequisites?",
      "level": "L8",
      "scoring": "inverse",
      "keywords": [
        "python",
        "java",
        "javascript",
        "prerequisite",
        "requirement",
        "coding"
      ],
      "top_k": 5,
      "approaches": {
        "Hybrid": {
          "recall": 0.16666666666666666,
          "mrr": 0.5,
          "ndcg": 0.6934264036172707,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 0.5,
          "effective_ndcg": 0.3065735963827293,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 0.16666666666666666,
          "mrr": 0.5,
          "ndcg": 0.6934264036172707,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 0.5,
          "effective_ndcg": 0.3065735963827293,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 0.0,
          "mrr": 0.0,
          "ndcg": 1.0,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.0,
          "passed": true
        },
        "BM25": {
          "recall": 0.0,
          "mrr": 0.0,
          "ndcg": 1.0,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.0,
          "passed": true
        },
        "Semantic": {
          "recall": 0.16666666666666666,
          "mrr": 0.5,
          "ndcg": 0.6934264036172707,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 0.5,
          "effective_ndcg": 0.3065735963827293,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.16666666666666666,
          "mrr": 0.5,
          "ndcg": 0.6934264036172707,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 0.5,
          "effective_ndcg": 0.3065735963827293,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.16666666666666666,
          "mrr": 0.5,
          "ndcg": 0.6934264036172707,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 0.5,
          "effective_ndcg": 0.3065735963827293,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.16666666666666666,
          "mrr": 0.5,
          "ndcg": 0.6934264036172707,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 0.5,
          "effective_ndcg": 0.3065735963827293,
          "passed": true
        }
      }
    },
    {
      "query": "What is the final exam format for the course?",
      "level": "L8",
      "scoring": "inverse",
      "keywords": [
        "exam",
        "test",
        "midterm",
        "final",
        "quiz",
        "grading"
      ],
      "top_k": 5,
      "approaches": {
        "Hybrid": {
          "recall": 0.16666666666666666,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 0.0,
          "effective_ndcg": 0.0,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 0.16666666666666666,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 0.0,
          "effective_ndcg": 0.0,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 0.3333333333333333,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.6666666666666667,
          "effective_mrr": 0.0,
          "effective_ndcg": 0.0,
          "passed": true
        },
        "BM25": {
          "recall": 0.16666666666666666,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 0.0,
          "effective_ndcg": 0.0,
          "passed": true
        },
        "Semantic": {
          "recall": 0.16666666666666666,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 0.0,
          "effective_ndcg": 0.0,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.16666666666666666,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 0.0,
          "effective_ndcg": 0.0,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.16666666666666666,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 0.0,
          "effective_ndcg": 0.0,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.16666666666666666,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 0.0,
          "effective_ndcg": 0.0,
          "passed": true
        }
      }
    },
    {
      "query": "Which VCs are no longer participating in the course this year?",
      "level": "L9",
      "scoring": "normal",
      "keywords": [
        "khosla",
        "lux",
        "link",
        "e14",
        "pillar",
        "two lanterns"
      ],
      "top_k": 15,
      "approaches": {
        "Hybrid": {
          "recall": 0.6666666666666666,
          "mrr": 1.0,
          "ndcg": 0.7031432329334039,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7031432329334039,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 0.6666666666666666,
          "mrr": 1.0,
          "ndcg": 0.7031432329334039,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7031432329334039,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 0.6666666666666666,
          "mrr": 1.0,
          "ndcg": 0.7414636530982025,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7414636530982025,
          "passed": true
        },
        "BM25": {
          "recall": 0.5,
          "mrr": 0.5,
          "ndcg": 0.7006233574948963,
          "effective_recall": 0.5,
          "effective_mrr": 0.5,
          "effective_ndcg": 0.7006233574948963,
          "passed": true
        },
        "Semantic": {
          "recall": 0.6666666666666666,
          "mrr": 1.0,
          "ndcg": 0.6821160297746383,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.6821160297746383,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.6666666666666666,
          "mrr": 1.0,
          "ndcg": 0.7178947288412965,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7178947288412965,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.6666666666666666,
          "mrr": 1.0,
          "ndcg": 0.7178947288412965,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7178947288412965,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.6666666666666666,
          "mrr": 1.0,
          "ndcg": 0.7178947288412965,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7178947288412965,
          "passed": true
        }
      }
    },
    {
      "query": "How have the demo day judging criteria evolved from Spring 2023 to Fall 2025?",
      "level": "L9",
      "scoring": "normal",
      "keywords": [
        "impact",
        "unique",
        "complete",
        "demo",
        "judge",
        "gigas scale",
        "criteria"
      ],
      "top_k": 10,
      "approaches": {
        "Hybrid": {
          "recall": 0.8571428571428571,
          "mrr": 1.0,
          "ndcg": 0.9211410805414261,
          "effective_recall": 0.8571428571428571,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9211410805414261,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 0.8571428571428571,
          "mrr": 1.0,
          "ndcg": 0.9189930317978608,
          "effective_recall": 0.8571428571428571,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9189930317978608,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 0.7142857142857143,
          "mrr": 1.0,
          "ndcg": 0.7546554012697665,
          "effective_recall": 0.7142857142857143,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7546554012697665,
          "passed": true
        },
        "BM25": {
          "recall": 0.2857142857142857,
          "mrr": 1.0,
          "ndcg": 0.9461595718627467,
          "effective_recall": 0.2857142857142857,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9461595718627467,
          "passed": false
        },
        "Semantic": {
          "recall": 0.8571428571428571,
          "mrr": 1.0,
          "ndcg": 0.9557911522471707,
          "effective_recall": 0.8571428571428571,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9557911522471707,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.8571428571428571,
          "mrr": 1.0,
          "ndcg": 0.7837581800467175,
          "effective_recall": 0.8571428571428571,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7837581800467175,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.8571428571428571,
          "mrr": 1.0,
          "ndcg": 0.7837581800467175,
          "effective_recall": 0.8571428571428571,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7837581800467175,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.8571428571428571,
          "mrr": 1.0,
          "ndcg": 0.7837581800467175,
          "effective_recall": 0.8571428571428571,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7837581800467175,
          "passed": true
        }
      }
    },
    {
      "query": "How has the number of student teams grown from Spring 2023 to Fall 2025?",
      "level": "L9",
      "scoring": "normal",
      "keywords": [
        "15",
        "24",
        "38",
        "teams",
        "presenting",
        "demo"
      ],
      "top_k": 5,
      "approaches": {
        "Hybrid": {
          "recall": 0.5,
          "mrr": 1.0,
          "ndcg": 0.960960846717329,
          "effective_recall": 0.5,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.960960846717329,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 0.5,
          "mrr": 1.0,
          "ndcg": 0.960960846717329,
          "effective_recall": 0.5,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.960960846717329,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 0.6666666666666666,
          "mrr": 1.0,
          "ndcg": 0.8986776544421414,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8986776544421414,
          "passed": true
        },
        "BM25": {
          "recall": 0.3333333333333333,
          "mrr": 1.0,
          "ndcg": 0.7747592084729605,
          "effective_recall": 0.3333333333333333,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7747592084729605,
          "passed": false
        },
        "Semantic": {
          "recall": 0.6666666666666666,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.6666666666666666,
          "mrr": 1.0,
          "ndcg": 0.960960846717329,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.960960846717329,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.6666666666666666,
          "mrr": 1.0,
          "ndcg": 0.960960846717329,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.960960846717329,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.6666666666666666,
          "mrr": 1.0,
          "ndcg": 0.960960846717329,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.960960846717329,
          "passed": true
        }
      }
    },
    {
      "query": "Why does Raskar say NANDA needs to involve universities and not just companies?",
      "level": "L10",
      "scoring": "normal",
      "keywords": [
        "university",
        "nanda",
        "trust",
        "decentralized",
        "neutral",
        "open"
      ],
      "top_k": 5,
      "approaches": {
        "Hybrid": {
          "recall": 0.8333333333333334,
          "mrr": 1.0,
          "ndcg": 0.9488136009556423,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9488136009556423,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 0.8333333333333334,
          "mrr": 1.0,
          "ndcg": 0.9488136009556423,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9488136009556423,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 0.6666666666666666,
          "mrr": 1.0,
          "ndcg": 0.9355095261428394,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9355095261428394,
          "passed": true
        },
        "BM25": {
          "recall": 0.6666666666666666,
          "mrr": 1.0,
          "ndcg": 0.8508342748471082,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8508342748471082,
          "passed": true
        },
        "Semantic": {
          "recall": 0.8333333333333334,
          "mrr": 1.0,
          "ndcg": 0.9343710124351232,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9343710124351232,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.8333333333333334,
          "mrr": 1.0,
          "ndcg": 0.9550479995674238,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9550479995674238,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.8333333333333334,
          "mrr": 1.0,
          "ndcg": 0.9550479995674238,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9550479995674238,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.8333333333333334,
          "mrr": 1.0,
          "ndcg": 0.9550479995674238,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9550479995674238,
          "passed": true
        }
      }
    },
    {
      "query": "What does gigascale impact mean in the context of this course?",
      "level": "L10",
      "scoring": "normal",
      "keywords": [
        "gigas scale",
        "billion",
        "impact",
        "people",
        "scale"
      ],
      "top_k": 5,
      "approaches": {
        "Hybrid": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.921396320854073,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.921396320854073,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.921396320854073,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.921396320854073,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.8025392158797567,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8025392158797567,
          "passed": true
        },
        "BM25": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "Semantic": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.921396320854073,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.921396320854073,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.8,
          "mrr": 1.0,
          "ndcg": 0.8241911108942168,
          "effective_recall": 0.8,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8241911108942168,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.8,
          "mrr": 1.0,
          "ndcg": 0.8241911108942168,
          "effective_recall": 0.8,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8241911108942168,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.8,
          "mrr": 1.0,
          "ndcg": 0.8241911108942168,
          "effective_recall": 0.8,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8241911108942168,
          "passed": true
        }
      }
    },
    {
      "query": "What is the quilt approach to building AI products that Raskar describes?",
      "level": "L10",
      "scoring": "normal",
      "keywords": [
        "quilt",
        "quilting",
        "model",
        "combine",
        "agent"
      ],
      "top_k": 5,
      "approaches": {
        "Hybrid": {
          "recall": 0.2,
          "mrr": 1.0,
          "ndcg": 0.9469024295259743,
          "effective_recall": 0.2,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9469024295259743,
          "passed": false
        },
        "Hybrid+Expand": {
          "recall": 0.2,
          "mrr": 1.0,
          "ndcg": 0.9469024295259743,
          "effective_recall": 0.2,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9469024295259743,
          "passed": false
        },
        "Hybrid+RRF": {
          "recall": 0.4,
          "mrr": 0.3333333333333333,
          "ndcg": 0.543791241910304,
          "effective_recall": 0.4,
          "effective_mrr": 0.3333333333333333,
          "effective_ndcg": 0.543791241910304,
          "passed": true
        },
        "BM25": {
          "recall": 0.6,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.6,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": true
        },
        "Semantic": {
          "recall": 0.2,
          "mrr": 1.0,
          "ndcg": 0.9469024295259743,
          "effective_recall": 0.2,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9469024295259743,
          "passed": false
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.2,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.2,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": false
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.2,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.2,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": false
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.2,
          "mrr": 1.0,
          "ndcg": 1.0,
          "effective_recall": 0.2,
          "effective_mrr": 1.0,
          "effective_ndcg": 1.0,
          "passed": false
        }
      }
    },
    {
      "query": "Name all the companies that have ever been judges or sponsors at demo days.",
      "level": "L11",
      "scoring": "normal",
      "keywords": [
        "mitsubishi",
        "state street",
        "ey",
        "mass challenge",
        "sponsor",
        "judge"
      ],
      "top_k": 15,
      "approaches": {
        "Hybrid": {
          "recall": 0.8333333333333334,
          "mrr": 1.0,
          "ndcg": 0.8626044552122213,
          "effective_recall": 0.8333333333333334,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8626044552122213,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 1.0,
          "mrr": 1.0,
          "ndcg": 0.8521860157869707,
          "effective_recall": 1.0,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8521860157869707,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 0.3333333333333333,
          "mrr": 1.0,
          "ndcg": 0.9964451522221968,
          "effective_recall": 0.3333333333333333,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9964451522221968,
          "passed": false
        },
        "BM25": {
          "recall": 0.6666666666666666,
          "mrr": 1.0,
          "ndcg": 0.856517514799784,
          "effective_recall": 0.6666666666666666,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.856517514799784,
          "passed": true
        },
        "Semantic": {
          "recall": 0.5,
          "mrr": 1.0,
          "ndcg": 0.9402268036207482,
          "effective_recall": 0.5,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9402268036207482,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.5,
          "mrr": 1.0,
          "ndcg": 0.9398058304490399,
          "effective_recall": 0.5,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9398058304490399,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.5,
          "mrr": 1.0,
          "ndcg": 0.9398058304490399,
          "effective_recall": 0.5,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9398058304490399,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.5,
          "mrr": 1.0,
          "ndcg": 0.9398058304490399,
          "effective_recall": 0.5,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9398058304490399,
          "passed": true
        }
      }
    },
    {
      "query": "What are all the healthcare or medical AI applications discussed across all semesters?",
      "level": "L11",
      "scoring": "normal",
      "keywords": [
        "health",
        "medical",
        "patient",
        "diabetic",
        "chest",
        "hospital",
        "clinical"
      ],
      "top_k": 10,
      "approaches": {
        "Hybrid": {
          "recall": 0.7142857142857143,
          "mrr": 1.0,
          "ndcg": 0.7826853730468758,
          "effective_recall": 0.7142857142857143,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7826853730468758,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 0.7142857142857143,
          "mrr": 1.0,
          "ndcg": 0.7826853730468758,
          "effective_recall": 0.7142857142857143,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7826853730468758,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 0.8571428571428571,
          "mrr": 1.0,
          "ndcg": 0.970562823022889,
          "effective_recall": 0.8571428571428571,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.970562823022889,
          "passed": true
        },
        "BM25": {
          "recall": 0.8571428571428571,
          "mrr": 1.0,
          "ndcg": 0.9833928888197015,
          "effective_recall": 0.8571428571428571,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.9833928888197015,
          "passed": true
        },
        "Semantic": {
          "recall": 0.7142857142857143,
          "mrr": 1.0,
          "ndcg": 0.7826853730468758,
          "effective_recall": 0.7142857142857143,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7826853730468758,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.42857142857142855,
          "mrr": 1.0,
          "ndcg": 0.8124614702704668,
          "effective_recall": 0.42857142857142855,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8124614702704668,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.42857142857142855,
          "mrr": 1.0,
          "ndcg": 0.8124614702704668,
          "effective_recall": 0.42857142857142855,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8124614702704668,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.42857142857142855,
          "mrr": 1.0,
          "ndcg": 0.8124614702704668,
          "effective_recall": 0.42857142857142855,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.8124614702704668,
          "passed": true
        }
      }
    },
    {
      "query": "Whose bio or role has changed the most across semesters of the course?",
      "level": "L12",
      "scoring": "normal",
      "keywords": [
        "werner",
        "john",
        "visiting lecturer",
        "link ventures",
        "santanu",
        "bhattacharya",
        "airtel",
        "media lab",
        "nanda",
        "chris pease"
      ],
      "top_k": 15,
      "approaches": {
        "Hybrid": {
          "recall": 0.9,
          "mrr": 0.3333333333333333,
          "ndcg": 0.4590777890428118,
          "effective_recall": 0.9,
          "effective_mrr": 0.3333333333333333,
          "effective_ndcg": 0.4590777890428118,
          "passed": true
        },
        "Hybrid+Expand": {
          "recall": 0.9,
          "mrr": 0.3333333333333333,
          "ndcg": 0.47021740025345654,
          "effective_recall": 0.9,
          "effective_mrr": 0.3333333333333333,
          "effective_ndcg": 0.47021740025345654,
          "passed": true
        },
        "Hybrid+RRF": {
          "recall": 0.4,
          "mrr": 0.3333333333333333,
          "ndcg": 0.6155622552380583,
          "effective_recall": 0.4,
          "effective_mrr": 0.3333333333333333,
          "effective_ndcg": 0.6155622552380583,
          "passed": true
        },
        "BM25": {
          "recall": 0.3,
          "mrr": 1.0,
          "ndcg": 0.7448938292196018,
          "effective_recall": 0.3,
          "effective_mrr": 1.0,
          "effective_ndcg": 0.7448938292196018,
          "passed": false
        },
        "Semantic": {
          "recall": 0.9,
          "mrr": 0.3333333333333333,
          "ndcg": 0.47742744029197676,
          "effective_recall": 0.9,
          "effective_mrr": 0.3333333333333333,
          "effective_ndcg": 0.47742744029197676,
          "passed": true
        },
        "LLM:gemini-2.0-flash-001": {
          "recall": 0.9,
          "mrr": 0.3333333333333333,
          "ndcg": 0.4052614906197505,
          "effective_recall": 0.9,
          "effective_mrr": 0.3333333333333333,
          "effective_ndcg": 0.4052614906197505,
          "passed": true
        },
        "LLM:llama-3.1-nemotron-70b": {
          "recall": 0.9,
          "mrr": 0.3333333333333333,
          "ndcg": 0.4052614906197505,
          "effective_recall": 0.9,
          "effective_mrr": 0.3333333333333333,
          "effective_ndcg": 0.4052614906197505,
          "passed": true
        },
        "LLM:llama-3.3-70b": {
          "recall": 0.9,
          "mrr": 0.3333333333333333,
          "ndcg": 0.4052614906197505,
          "effective_recall": 0.9,
          "effective_mrr": 0.3333333333333333,
          "effective_ndcg": 0.4052614906197505,
          "passed": true
        }
      }
    }
  ],
  "aggregates": {
    "Hybrid": {
      "Recall@K": 0.7214285714285714,
      "MRR": 0.8130952380952381,
      "NDCG@K": 0.7615025384576383,
      "pass@1": 0.9428571428571428,
      "pass@3": 1.0,
      "pass^3": 0.8381807580174927,
      "pass_rate": 0.9428571428571428,
      "n_passed": 33,
      "n_total": 35
    },
    "Hybrid+Expand": {
      "Recall@K": 0.7261904761904763,
      "MRR": 0.8130952380952381,
      "NDCG@K": 0.7686597808026195,
      "pass@1": 0.9428571428571428,
      "pass@3": 1.0,
      "pass^3": 0.8381807580174927,
      "pass_rate": 0.9428571428571428,
      "n_passed": 33,
      "n_total": 35
    },
    "Hybrid+RRF": {
      "Recall@K": 0.7167346938775511,
      "MRR": 0.8847619047619047,
      "NDCG@K": 0.7959660004632915,
      "pass@1": 0.9142857142857143,
      "pass@3": 0.9998472116119175,
      "pass^3": 0.7642682215743439,
      "pass_rate": 0.9142857142857143,
      "n_passed": 32,
      "n_total": 35
    },
    "BM25": {
      "Recall@K": 0.7052380952380952,
      "MRR": 0.8771428571428571,
      "NDCG@K": 0.8091735837264494,
      "pass@1": 0.8285714285714285,
      "pass@3": 0.9969442322383499,
      "pass^3": 0.5688396501457728,
      "pass_rate": 0.8285714285714286,
      "n_passed": 29,
      "n_total": 35
    },
    "Semantic": {
      "Recall@K": 0.6930612244897959,
      "MRR": 0.8307692307692308,
      "NDCG@K": 0.7750076609271834,
      "pass@1": 0.8857142857142857,
      "pass@3": 0.99938884644767,
      "pass^3": 0.6948338192419824,
      "pass_rate": 0.8857142857142857,
      "n_passed": 31,
      "n_total": 35
    },
    "LLM:gemini-2.0-flash-001": {
      "Recall@K": 0.6715646258503402,
      "MRR": 0.8333333333333334,
      "NDCG@K": 0.8076623969949023,
      "pass@1": 0.8285714285714285,
      "pass@3": 0.9969442322383499,
      "pass^3": 0.5688396501457728,
      "pass_rate": 0.8285714285714286,
      "n_passed": 29,
      "n_total": 35
    },
    "LLM:llama-3.1-nemotron-70b": {
      "Recall@K": 0.664421768707483,
      "MRR": 0.8333333333333334,
      "NDCG@K": 0.7945504346059484,
      "pass@1": 0.8285714285714285,
      "pass@3": 0.9969442322383499,
      "pass^3": 0.5688396501457728,
      "pass_rate": 0.8285714285714286,
      "n_passed": 29,
      "n_total": 35
    },
    "LLM:llama-3.3-70b": {
      "Recall@K": 0.664421768707483,
      "MRR": 0.8047619047619048,
      "NDCG@K": 0.8126982567278842,
      "pass@1": 0.8285714285714285,
      "pass@3": 0.9969442322383499,
      "pass^3": 0.5688396501457728,
      "pass_rate": 0.8285714285714286,
      "n_passed": 29,
      "n_total": 35
    }
  },
  "per_level": {
    "L1": {
      "n": 3,
      "approaches": {
        "Hybrid": {
          "mean_recall": 0.8333333333333334,
          "mean_mrr": 0.7777777777777778,
          "mean_ndcg": 0.8333333333333334
        },
        "Hybrid+Expand": {
          "mean_recall": 0.8333333333333334,
          "mean_mrr": 0.7777777777777778,
          "mean_ndcg": 0.8333333333333334
        },
        "Hybrid+RRF": {
          "mean_recall": 0.8333333333333334,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.9942973606522293
        },
        "BM25": {
          "mean_recall": 0.8333333333333334,
          "mean_mrr": 1.0,
          "mean_ndcg": 1.0
        },
        "Semantic": {
          "mean_recall": 0.9166666666666666,
          "mean_mrr": 1.0,
          "mean_ndcg": 1.0
        },
        "LLM:gemini-2.0-flash-001": {
          "mean_recall": 1.0,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.9639826065740476
        },
        "LLM:llama-3.1-nemotron-70b": {
          "mean_recall": 0.8333333333333334,
          "mean_mrr": 1.0,
          "mean_ndcg": 1.0
        },
        "LLM:llama-3.3-70b": {
          "mean_recall": 0.8333333333333334,
          "mean_mrr": 1.0,
          "mean_ndcg": 1.0
        }
      }
    },
    "L2": {
      "n": 2,
      "approaches": {
        "Hybrid": {
          "mean_recall": 0.7083333333333333,
          "mean_mrr": 0.6666666666666666,
          "mean_ndcg": 0.7948390746907423
        },
        "Hybrid+Expand": {
          "mean_recall": 0.7083333333333333,
          "mean_mrr": 0.6666666666666666,
          "mean_ndcg": 0.7948390746907423
        },
        "Hybrid+RRF": {
          "mean_recall": 0.7083333333333333,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.9849612681506822
        },
        "BM25": {
          "mean_recall": 0.7083333333333333,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.9350432784897632
        },
        "Semantic": {
          "mean_recall": 0.7083333333333333,
          "mean_mrr": 0.6666666666666666,
          "mean_ndcg": 0.7286684863663728
        },
        "LLM:gemini-2.0-flash-001": {
          "mean_recall": 0.7083333333333333,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.8889024546064751
        },
        "LLM:llama-3.1-nemotron-70b": {
          "mean_recall": 0.7083333333333333,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.9524882791605083
        },
        "LLM:llama-3.3-70b": {
          "mean_recall": 0.875,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.8748408949045399
        }
      }
    },
    "L3": {
      "n": 4,
      "approaches": {
        "Hybrid": {
          "mean_recall": 0.8125,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.7634568777845091
        },
        "Hybrid+Expand": {
          "mean_recall": 0.8125,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.8203542360307873
        },
        "Hybrid+RRF": {
          "mean_recall": 0.8125,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.7388765921900742
        },
        "BM25": {
          "mean_recall": 0.8333333333333334,
          "mean_mrr": 0.875,
          "mean_ndcg": 0.8774012567589293
        },
        "Semantic": {
          "mean_recall": 0.6125,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.7244030023014727
        },
        "LLM:gemini-2.0-flash-001": {
          "mean_recall": 0.7708333333333334,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.831209647618635
        },
        "LLM:llama-3.1-nemotron-70b": {
          "mean_recall": 0.7708333333333334,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.7974545153461324
        },
        "LLM:llama-3.3-70b": {
          "mean_recall": 0.8125,
          "mean_mrr": 0.875,
          "mean_ndcg": 0.8765358865916698
        }
      }
    },
    "L4": {
      "n": 2,
      "approaches": {
        "Hybrid": {
          "mean_recall": 1.0,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.8151206572295053
        },
        "Hybrid+Expand": {
          "mean_recall": 1.0,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.8151206572295053
        },
        "Hybrid+RRF": {
          "mean_recall": 1.0,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.7869782997343123
        },
        "BM25": {
          "mean_recall": 0.7,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.8855957810471654
        },
        "Semantic": {
          "mean_recall": 1.0,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.9682410180927637
        },
        "LLM:gemini-2.0-flash-001": {
          "mean_recall": 1.0,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.9679990274445897
        },
        "LLM:llama-3.1-nemotron-70b": {
          "mean_recall": 1.0,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.6988161337879291
        },
        "LLM:llama-3.3-70b": {
          "mean_recall": 1.0,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.9814513968494162
        }
      }
    },
    "L5": {
      "n": 3,
      "approaches": {
        "Hybrid": {
          "mean_recall": 0.6166666666666667,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.8430697801383021
        },
        "Hybrid+Expand": {
          "mean_recall": 0.6166666666666667,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.8500345035328173
        },
        "Hybrid+RRF": {
          "mean_recall": 0.7388888888888889,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.8814181057448452
        },
        "BM25": {
          "mean_recall": 0.8055555555555555,
          "mean_mrr": 1.0,
          "mean_ndcg": 1.0
        },
        "Semantic": {
          "mean_recall": 0.6833333333333332,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.7674254662469385
        },
        "LLM:gemini-2.0-flash-001": {
          "mean_recall": 0.48888888888888893,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.8739116689744876
        },
        "LLM:llama-3.1-nemotron-70b": {
          "mean_recall": 0.5722222222222223,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.8669929367758291
        },
        "LLM:llama-3.3-70b": {
          "mean_recall": 0.4055555555555556,
          "mean_mrr": 0.8333333333333334,
          "mean_ndcg": 0.8366171140006838
        }
      }
    },
    "L6": {
      "n": 5,
      "approaches": {
        "Hybrid": {
          "mean_recall": 0.58,
          "mean_mrr": 0.6666666666666667,
          "mean_ndcg": 0.8508477621306177
        },
        "Hybrid+Expand": {
          "mean_recall": 0.58,
          "mean_mrr": 0.6666666666666667,
          "mean_ndcg": 0.8508477621306177
        },
        "Hybrid+RRF": {
          "mean_recall": 0.6599999999999999,
          "mean_mrr": 0.8,
          "mean_ndcg": 0.8777448318627357
        },
        "BM25": {
          "mean_recall": 0.7666666666666667,
          "mean_mrr": 0.8400000000000001,
          "mean_ndcg": 0.7496198934271302
        },
        "Semantic": {
          "mean_recall": 0.6133333333333333,
          "mean_mrr": 0.6666666666666667,
          "mean_ndcg": 0.8037329667578119
        },
        "LLM:gemini-2.0-flash-001": {
          "mean_recall": 0.5,
          "mean_mrr": 0.4666666666666667,
          "mean_ndcg": 0.8666649074702122
        },
        "LLM:llama-3.1-nemotron-70b": {
          "mean_recall": 0.5,
          "mean_mrr": 0.4666666666666667,
          "mean_ndcg": 0.8666649074702122
        },
        "LLM:llama-3.3-70b": {
          "mean_recall": 0.5,
          "mean_mrr": 0.4666666666666667,
          "mean_ndcg": 0.8666649074702122
        }
      }
    },
    "L7": {
      "n": 4,
      "approaches": {
        "Hybrid": {
          "mean_recall": 0.6654761904761904,
          "mean_mrr": 0.78125,
          "mean_ndcg": 0.7387450834596612
        },
        "Hybrid+Expand": {
          "mean_recall": 0.6654761904761904,
          "mean_mrr": 0.78125,
          "mean_ndcg": 0.7396067724256264
        },
        "Hybrid+RRF": {
          "mean_recall": 0.549404761904762,
          "mean_mrr": 0.875,
          "mean_ndcg": 0.8677999592971
        },
        "BM25": {
          "mean_recall": 0.5601190476190476,
          "mean_mrr": 0.875,
          "mean_ndcg": 0.8721992950724855
        },
        "Semantic": {
          "mean_recall": 0.5047619047619047,
          "mean_mrr": 0.7692307692307693,
          "mean_ndcg": 0.8095727656745981
        },
        "LLM:gemini-2.0-flash-001": {
          "mean_recall": 0.5047619047619047,
          "mean_mrr": 0.8125,
          "mean_ndcg": 0.784740838233476
        },
        "LLM:llama-3.1-nemotron-70b": {
          "mean_recall": 0.5047619047619047,
          "mean_mrr": 0.8125,
          "mean_ndcg": 0.784740838233476
        },
        "LLM:llama-3.3-70b": {
          "mean_recall": 0.5047619047619047,
          "mean_mrr": 0.8125,
          "mean_ndcg": 0.784740838233476
        }
      }
    },
    "L8": {
      "n": 3,
      "approaches": {
        "Hybrid": {
          "mean_recall": 0.7222222222222223,
          "mean_mrr": 0.3333333333333333,
          "mean_ndcg": 0.21122941910080298
        },
        "Hybrid+Expand": {
          "mean_recall": 0.7222222222222223,
          "mean_mrr": 0.3333333333333333,
          "mean_ndcg": 0.21122941910080298
        },
        "Hybrid+RRF": {
          "mean_recall": 0.8333333333333334,
          "mean_mrr": 0.6,
          "mean_ndcg": 0.20438239758848611
        },
        "BM25": {
          "mean_recall": 0.7777777777777778,
          "mean_mrr": 0.3333333333333333,
          "mean_ndcg": 0.025371663791253884
        },
        "Semantic": {
          "mean_recall": 0.7222222222222223,
          "mean_mrr": 0.3333333333333333,
          "mean_ndcg": 0.21122941910080298
        },
        "LLM:gemini-2.0-flash-001": {
          "mean_recall": 0.7222222222222223,
          "mean_mrr": 0.4166666666666667,
          "mean_ndcg": 0.2813966553027001
        },
        "LLM:llama-3.1-nemotron-70b": {
          "mean_recall": 0.7222222222222223,
          "mean_mrr": 0.4166666666666667,
          "mean_ndcg": 0.2813966553027001
        },
        "LLM:llama-3.3-70b": {
          "mean_recall": 0.7222222222222223,
          "mean_mrr": 0.4166666666666667,
          "mean_ndcg": 0.2813966553027001
        }
      }
    },
    "L9": {
      "n": 3,
      "approaches": {
        "Hybrid": {
          "mean_recall": 0.6746031746031745,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.8617483867307195
        },
        "Hybrid+Expand": {
          "mean_recall": 0.6746031746031745,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.8610323704828646
        },
        "Hybrid+RRF": {
          "mean_recall": 0.6825396825396824,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.7982655696033701
        },
        "BM25": {
          "mean_recall": 0.373015873015873,
          "mean_mrr": 0.8333333333333334,
          "mean_ndcg": 0.8071807126102012
        },
        "Semantic": {
          "mean_recall": 0.7301587301587301,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.8793023940072696
        },
        "LLM:gemini-2.0-flash-001": {
          "mean_recall": 0.7301587301587301,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.8208712518684477
        },
        "LLM:llama-3.1-nemotron-70b": {
          "mean_recall": 0.7301587301587301,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.8208712518684477
        },
        "LLM:llama-3.3-70b": {
          "mean_recall": 0.7301587301587301,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.8208712518684477
        }
      }
    },
    "L10": {
      "n": 3,
      "approaches": {
        "Hybrid": {
          "mean_recall": 0.6777777777777777,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.9390374504452298
        },
        "Hybrid+Expand": {
          "mean_recall": 0.6777777777777777,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.9390374504452298
        },
        "Hybrid+RRF": {
          "mean_recall": 0.6888888888888888,
          "mean_mrr": 0.7777777777777778,
          "mean_ndcg": 0.7606133279776334
        },
        "BM25": {
          "mean_recall": 0.7555555555555555,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.9502780916157026
        },
        "Semantic": {
          "mean_recall": 0.6777777777777777,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.9342232542717235
        },
        "LLM:gemini-2.0-flash-001": {
          "mean_recall": 0.6111111111111112,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.9264130368205469
        },
        "LLM:llama-3.1-nemotron-70b": {
          "mean_recall": 0.6111111111111112,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.9264130368205469
        },
        "LLM:llama-3.3-70b": {
          "mean_recall": 0.6111111111111112,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.9264130368205469
        }
      }
    },
    "L11": {
      "n": 2,
      "approaches": {
        "Hybrid": {
          "mean_recall": 0.7738095238095238,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.8226449141295485
        },
        "Hybrid+Expand": {
          "mean_recall": 0.8571428571428572,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.8174356944169232
        },
        "Hybrid+RRF": {
          "mean_recall": 0.5952380952380952,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.9835039876225429
        },
        "BM25": {
          "mean_recall": 0.7619047619047619,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.9199552018097428
        },
        "Semantic": {
          "mean_recall": 0.6071428571428572,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.861456088333812
        },
        "LLM:gemini-2.0-flash-001": {
          "mean_recall": 0.4642857142857143,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.8761336503597533
        },
        "LLM:llama-3.1-nemotron-70b": {
          "mean_recall": 0.4642857142857143,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.8761336503597533
        },
        "LLM:llama-3.3-70b": {
          "mean_recall": 0.4642857142857143,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.8761336503597533
        }
      }
    },
    "L12": {
      "n": 1,
      "approaches": {
        "Hybrid": {
          "mean_recall": 0.9,
          "mean_mrr": 0.3333333333333333,
          "mean_ndcg": 0.4590777890428118
        },
        "Hybrid+Expand": {
          "mean_recall": 0.9,
          "mean_mrr": 0.3333333333333333,
          "mean_ndcg": 0.47021740025345654
        },
        "Hybrid+RRF": {
          "mean_recall": 0.4,
          "mean_mrr": 0.3333333333333333,
          "mean_ndcg": 0.6155622552380583
        },
        "BM25": {
          "mean_recall": 0.3,
          "mean_mrr": 1.0,
          "mean_ndcg": 0.7448938292196018
        },
        "Semantic": {
          "mean_recall": 0.9,
          "mean_mrr": 0.3333333333333333,
          "mean_ndcg": 0.47742744029197676
        },
        "LLM:gemini-2.0-flash-001": {
          "mean_recall": 0.9,
          "mean_mrr": 0.3333333333333333,
          "mean_ndcg": 0.4052614906197505
        },
        "LLM:llama-3.1-nemotron-70b": {
          "mean_recall": 0.9,
          "mean_mrr": 0.3333333333333333,
          "mean_ndcg": 0.4052614906197505
        },
        "LLM:llama-3.3-70b": {
          "mean_recall": 0.9,
          "mean_mrr": 0.3333333333333333,
          "mean_ndcg": 0.4052614906197505
        }
      }
    }
  },
  "weight_sweep": [
    {
      "kw": 1.0,
      "sw": 0.0,
      "label": "BM25=100% Sem=0%",
      "mean_recall": 0.5248299319727892,
      "pass_rate": 0.6285714285714286
    },
    {
      "kw": 0.9,
      "sw": 0.1,
      "label": "BM25=90% Sem=10%",
      "mean_recall": 0.6525850340136055,
      "pass_rate": 0.8
    },
    {
      "kw": 0.8,
      "sw": 0.2,
      "label": "BM25=80% Sem=20%",
      "mean_recall": 0.6498639455782312,
      "pass_rate": 0.8285714285714286
    },
    {
      "kw": 0.7,
      "sw": 0.3,
      "label": "BM25=70% Sem=30%",
      "mean_recall": 0.6693877551020407,
      "pass_rate": 0.8571428571428571
    },
    {
      "kw": 0.6,
      "sw": 0.4,
      "label": "BM25=60% Sem=40%",
      "mean_recall": 0.7025850340136055,
      "pass_rate": 0.9142857142857143
    },
    {
      "kw": 0.5,
      "sw": 0.5,
      "label": "BM25=50% Sem=50%",
      "mean_recall": 0.6878231292517006,
      "pass_rate": 0.8857142857142857
    },
    {
      "kw": 0.4,
      "sw": 0.6,
      "label": "BM25=40% Sem=60%",
      "mean_recall": 0.7166666666666667,
      "pass_rate": 0.9142857142857143
    },
    {
      "kw": 0.3,
      "sw": 0.7,
      "label": "BM25=30% Sem=70%",
      "mean_recall": 0.7214285714285714,
      "pass_rate": 0.9428571428571428
    },
    {
      "kw": 0.2,
      "sw": 0.8,
      "label": "BM25=20% Sem=80%",
      "mean_recall": 0.7230612244897959,
      "pass_rate": 0.9142857142857143
    },
    {
      "kw": 0.1,
      "sw": 0.9,
      "label": "BM25=10% Sem=90%",
      "mean_recall": 0.6992517006802721,
      "pass_rate": 0.8857142857142857
    },
    {
      "kw": 0.0,
      "sw": 1.0,
      "label": "BM25=0% Sem=100%",
      "mean_recall": 0.6808163265306123,
      "pass_rate": 0.8571428571428571
    },
    {
      "kw": null,
      "sw": null,
      "label": "LLM:gemini-2.0-flash-001",
      "mean_recall": 0.6715646258503402,
      "pass_rate": 0.8285714285714286
    },
    {
      "kw": null,
      "sw": null,
      "label": "LLM:llama-3.1-nemotron-70b",
      "mean_recall": 0.664421768707483,
      "pass_rate": 0.8285714285714286
    },
    {
      "kw": null,
      "sw": null,
      "label": "LLM:llama-3.3-70b",
      "mean_recall": 0.664421768707483,
      "pass_rate": 0.8285714285714286
    }
  ]
}